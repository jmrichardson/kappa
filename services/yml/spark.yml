  spark:
    container_name: spark
    hostname: spark1
    build: spark/.
    image: spark
    network_mode: "host"
    depends_on:
      - hadoop
      - hive
    environment:
      - SPARK_NO_DAEMONIZE=true
    volumes:
      - ./spark/slaves:/opt/spark/conf/slaves
      - ./spark/supervisord.conf:/etc/supervisor/conf.d/supervisord.conf
